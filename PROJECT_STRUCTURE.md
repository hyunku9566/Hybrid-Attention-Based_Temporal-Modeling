# Baseline ADL Recognition - Project Structure

## üìÅ Complete Directory Structure

```
baseline-adl-recognition/
‚îú‚îÄ‚îÄ README.md                    # Main project documentation
‚îú‚îÄ‚îÄ LICENSE                      # MIT License
‚îú‚îÄ‚îÄ CONTRIBUTING.md              # Contribution guidelines
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ .gitignore                   # Git ignore rules
‚îÇ
‚îú‚îÄ‚îÄ data/                        # Data preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ README.md               # Data format documentation
‚îÇ   ‚îú‚îÄ‚îÄ build_features.py       # Feature extraction script
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Raw sensor CSV files (not included)
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/             # Sensor embeddings (optional)
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Processed datasets (not included)
‚îÇ
‚îú‚îÄ‚îÄ models/                      # Model architecture
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py             # Package initialization
‚îÇ   ‚îú‚îÄ‚îÄ README.md               # Architecture documentation
‚îÇ   ‚îú‚îÄ‚îÄ components.py           # TCNBlock, AdditiveAttention, FocalLoss
‚îÇ   ‚îî‚îÄ‚îÄ baseline_model.py       # Main BaselineModel class
‚îÇ
‚îú‚îÄ‚îÄ train/                       # Training scripts
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py             # Package initialization
‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Training configuration
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                # Training utilities
‚îÇ   ‚îî‚îÄ‚îÄ train.py                # Main training script
‚îÇ
‚îú‚îÄ‚îÄ evaluate/                    # Evaluation scripts
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py             # Package initialization
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py             # Model evaluation
‚îÇ   ‚îî‚îÄ‚îÄ visualize.py            # Attention visualization
‚îÇ
‚îú‚îÄ‚îÄ scripts/                     # Helper scripts
‚îÇ   ‚îú‚îÄ‚îÄ quick_start.sh          # Complete workflow script
‚îÇ   ‚îî‚îÄ‚îÄ evaluate_model.sh       # Quick evaluation script
‚îÇ
‚îú‚îÄ‚îÄ checkpoints/                 # Saved model weights
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep                # (Checkpoint files not tracked in git)
‚îÇ
‚îú‚îÄ‚îÄ results/                     # Evaluation results
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep                # (Result files not tracked in git)
‚îÇ
‚îî‚îÄ‚îÄ docs/                        # Additional documentation
    ‚îî‚îÄ‚îÄ .gitkeep                # (Paper drafts, experiments notes)
```

## üìÑ File Descriptions

### Root Directory

- **README.md** (8.7 KB): Comprehensive project documentation with:
  - Architecture overview and diagram
  - Performance comparison table
  - Installation and usage instructions
  - Quick start guide
  - Citation information

- **LICENSE** (1.1 KB): MIT License

- **CONTRIBUTING.md** (5.3 KB): Guidelines for contributors including:
  - How to report issues
  - Pull request process
  - Coding standards
  - Testing requirements

- **requirements.txt** (351 B): Python dependencies
  - Core: torch>=2.0.0, numpy, pandas, scikit-learn
  - Visualization: matplotlib, seaborn, plotly
  - Utils: tqdm, tabulate

- **.gitignore** (734 B): Excludes:
  - Python cache files (\*.pyc, __pycache__)
  - Model weights (\*.pt, \*.pth)
  - Data files (\*.csv, \*.npz)
  - Results (plots, logs)

### data/ Directory (3 files, ~11 KB)

- **README.md** (3.2 KB): Data format and preprocessing documentation
- **build_features.py** (8.2 KB): Feature extraction script
  - Sliding window extraction (T=100, stride=5)
  - Time feature encoding
  - Sensor embedding integration
  - Output: dataset.npz with X, y, filenames, class_names

### models/ Directory (4 files, ~17 KB)

- **__init__.py** (611 B): Package exports
- **README.md** (4.0 KB): Architecture documentation
- **components.py** (6.7 KB): Building blocks
  - `TCNBlock`: Dilated causal convolutions
  - `AdditiveAttention`: Bahdanau-style attention
  - `FocalLoss`: Class imbalance handling
- **baseline_model.py** (6.5 KB): Main model class
  - Architecture: Linear ‚Üí TCN(3) ‚Üí BiGRU ‚Üí Attention ‚Üí Classifier
  - Methods: forward(), count_parameters()

### train/ Directory (4 files, ~24 KB)

- **__init__.py** (628 B): Package exports
- **config.py** (4.2 KB): Training configuration
  - `TrainingConfig`: Default hyperparameters
  - Alternative configs: FastTrainConfig, LargeModelConfig, SmallModelConfig
- **utils.py** (10.7 KB): Training utilities
  - `ADLDataset`: PyTorch Dataset
  - `load_data()`: Data loading and splitting
  - `create_dataloaders()`: DataLoader creation with WeightedRandomSampler
  - `train_epoch()`, `evaluate()`: Training loop functions
  - `plot_training_history()`, `plot_confusion_matrix()`: Visualization
- **train.py** (9.2 KB): Main training script
  - CLI interface with argparse
  - Training loop with early stopping
  - Checkpoint saving
  - Test set evaluation

### evaluate/ Directory (3 files, ~15 KB)

- **__init__.py** (74 B): Package initialization
- **evaluate.py** (6.5 KB): Model evaluation
  - Comprehensive metrics calculation
  - Per-class precision/recall/F1
  - Confusion matrix
  - Results saved to JSON
- **visualize.py** (9.1 KB): Visualization tools
  - Attention weight plots
  - Prediction confidence plots
  - Sensor activation plots

### scripts/ Directory (2 files, ~3.7 KB)

- **quick_start.sh** (2.7 KB): Complete workflow
  - Data preprocessing ‚Üí Training ‚Üí Evaluation ‚Üí Visualization
  - Executable: `chmod +x scripts/quick_start.sh`
- **evaluate_model.sh** (1.0 KB): Quick evaluation
  - Usage: `./evaluate_model.sh <checkpoint_path>`

### Other Directories

- **checkpoints/**: Saved model weights (.pt files)
  - `.gitkeep` placeholder (actual weights not tracked)
  - Expected: `best_baseline.pt`, `last_epoch.pt`

- **results/**: Evaluation outputs
  - `.gitkeep` placeholder
  - Expected: confusion matrices, classification reports, visualizations

- **docs/**: Additional documentation
  - `.gitkeep` placeholder
  - For paper drafts, experiment notes, etc.

## üìä Key Statistics

- **Total Python files**: 13
- **Total lines of code**: ~2,500
- **Documentation files**: 5 (README, CONTRIBUTING, 3√ó module READMEs)
- **Shell scripts**: 2
- **Packages**: 3 (models, train, evaluate)

## üîó File Dependencies

```
train.py
  ‚îú‚îÄ‚îÄ models/baseline_model.py
  ‚îÇ   ‚îî‚îÄ‚îÄ models/components.py
  ‚îú‚îÄ‚îÄ train/config.py
  ‚îî‚îÄ‚îÄ train/utils.py

evaluate.py
  ‚îú‚îÄ‚îÄ models/baseline_model.py
  ‚îÇ   ‚îî‚îÄ‚îÄ models/components.py
  ‚îî‚îÄ‚îÄ train/utils.py (for data loading)

visualize.py
  ‚îî‚îÄ‚îÄ models/baseline_model.py
      ‚îî‚îÄ‚îÄ models/components.py
```

## üöÄ Usage Workflows

### Workflow 1: From Scratch

```bash
# 1. Prepare data
python data/build_features.py --data_dir data/raw --output data/processed/dataset.npz

# 2. Train model
python train/train.py --data_path data/processed/dataset.npz --epochs 30

# 3. Evaluate
python evaluate/evaluate.py --checkpoint checkpoints/best_baseline.pt

# 4. Visualize
python evaluate/visualize.py --checkpoint checkpoints/best_baseline.pt
```

### Workflow 2: Quick Start

```bash
cd scripts
./quick_start.sh
```

### Workflow 3: Evaluation Only

```bash
cd scripts
./evaluate_model.sh ../checkpoints/best_baseline.pt
```

## üì¶ Package Organization

### models Package
- **Purpose**: Model architecture components
- **Exports**: BaselineModel, TCNBlock, AdditiveAttention, FocalLoss
- **Usage**: `from models import BaselineModel`

### train Package
- **Purpose**: Training utilities and configuration
- **Exports**: TrainingConfig, data loaders, training functions
- **Usage**: `from train import TrainingConfig, load_data`

### evaluate Package
- **Purpose**: Evaluation and visualization
- **Exports**: None (use scripts directly)
- **Usage**: Run scripts via CLI

## üéØ Next Steps

1. **Add raw data** to `data/raw/` directory
2. **Run preprocessing**: `python data/build_features.py`
3. **Train model**: `python train/train.py`
4. **Evaluate**: `python evaluate/evaluate.py --checkpoint checkpoints/best_baseline.pt`
5. **Visualize**: `python evaluate/visualize.py --checkpoint checkpoints/best_baseline.pt`

## üìù Notes

- All Python files have comprehensive docstrings
- Scripts include CLI interfaces with `--help` option
- Code follows PEP 8 style guide
- Ready for GitHub upload and public release
- MIT License allows free use and modification

---

**Total Project Size**: ~70 KB (excluding data and checkpoints)  
**Last Updated**: 2024-10-29
